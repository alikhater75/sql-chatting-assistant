{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build a chatting assistant for SQL data\n",
    "\n",
    "\n",
    "Developing a conversational assistant for structured datasets involves a distinct approach compared to handling unstructured text data. While unstructured data often leverages vector search for generating responses, working with structured data typically involves constructing and executing queries in a domain-specific language like SQL. In this task, we will explore how to create a Q&A system tailored for structured procurement data, leveraging techniques that allow an AI-driven conversational interface to retrieve and interpret relevant insights from a tabular dataset. The goal is to build a prototype capable of handling user queries effectively.\n",
    "\n",
    "## Security note \n",
    "\n",
    "Building Q&A systems of SQL databases requires executing model-generated SQL queries. There are inherent risks in doing this. Make sure that your database connection permissions are always scoped as narrowly as possible for your chain/agent's needs. This will mitigate though not eliminate the risks of building a model-driven system\n",
    "\n",
    "\n",
    "## Architecture\n",
    "\n",
    "At a high-level, the steps of these systems are:\n",
    "\n",
    "1. **Convert question to SQL query**: Model converts user input to a SQL query.\n",
    "2. **Execute SQL query**: Execute the query.\n",
    "3. **Answer the question**: Model responds to user input using the query results.\n",
    "\n",
    "## Setup\n",
    "\n",
    "First, get required packages and set environment variables:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -illow (c:\\users\\alikh\\anaconda3\\envs\\sm_ct\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\alikh\\anaconda3\\envs\\sm_ct\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -illow (c:\\users\\alikh\\anaconda3\\envs\\sm_ct\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\alikh\\anaconda3\\envs\\sm_ct\\lib\\site-packages)\n"
     ]
    }
   ],
   "source": [
    "%%capture --no-stderr\n",
    "%pip install --upgrade --quiet langchain-community langchainhub langgraph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing and Conversion of Procurement Dataset to SQLite Database\n",
    "\n",
    "This section preprocesses the procurement dataset and converts it into an SQLite database.\n",
    "\n",
    "### Steps:\n",
    "1. **Load the dataset:** Read the dataset from a CSV file into a Pandas DataFrame.\n",
    "2. **Handle missing values:** Fill missing values in critical columns (`Unit Price` and `Total Price`) with zero.\n",
    "3. **Format price columns:** Convert price-related columns from string format (e.g., \"$123.45\") to numerical format for calculations.\n",
    "4. **Rename columns:** Replace spaces and hyphens in column names with underscores to ensure compatibility with SQL.\n",
    "5. **Convert date columns:** Transform `Creation Date` and `Purchase Date` into datetime objects for date-based queries.\n",
    "6. **Feature extraction:** Derive additional columns:\n",
    "   - Day, month, year, and quarter from the `Creation Date` and `Purchase Date` columns for simplified temporal analysis.\n",
    "7. **Save to SQLite database:** Store the cleaned and enriched DataFrame as a table in an SQLite database (`consumption.db`).\n",
    "\n",
    "### Purpose:\n",
    "The resulting SQLite database will be utilized with LangChain to develop a conversational AI system capable of querying and analyzing procurement data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "346018"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sqlite3\n",
    "import pandas as pd \n",
    "\n",
    "df = pd.read_csv(\"PURCHASE ORDER DATA EXTRACT 2012-2015_0.csv\")\n",
    "df[\"Unit Price\"].fillna(0, inplace=True)\n",
    "df[\"Total Price\"].fillna(0, inplace=True)\n",
    "\n",
    "df[\"Unit Price\"] = df[\"Unit Price\"].apply(lambda x: float(x[1:] if x else x))\n",
    "df[\"Total Price\"] = df[\"Total Price\"].apply(lambda x: float(x[1:] if x else x))\n",
    "\n",
    "df.columns = [c.replace(\" \", \"_\") for c in df.columns]\n",
    "df.columns = [c.replace(\"-\", \"_\") for c in df.columns]\n",
    "\n",
    "# Convert dates to datetime objects\n",
    "df['Creation_Date'] = pd.to_datetime(df['Creation_Date'], format='%m/%d/%Y', errors='coerce')\n",
    "df['Purchase_Date'] = pd.to_datetime(df['Purchase_Date'], format='%m/%d/%Y', errors='coerce')\n",
    "\n",
    "# Extract day, month, and year from Creation_Date\n",
    "df['Creation_Date_Day'] = df['Creation_Date'].dt.day\n",
    "df['Creation_Date_Month'] = df['Creation_Date'].dt.month\n",
    "df['Creation_Date_Year'] = df['Creation_Date'].dt.year\n",
    "df['Creation_Date_Quarter'] = df['Creation_Date'].dt.to_period('Q').astype(str)\n",
    "\n",
    "# Extract day, month, and year from Purchase_Date\n",
    "df['Purchase_Date_Day'] = df['Purchase_Date'].dt.day\n",
    "df['Purchase_Date_Month'] = df['Purchase_Date'].dt.month\n",
    "df['Purchase_Date_Year'] = df['Purchase_Date'].dt.year\n",
    "df['Purchase_Date_Quarter'] = df['Creation_Date'].dt.to_period('Q').astype(str)\n",
    "\n",
    "conn = sqlite3.connect('consumption.db',check_same_thread=False)\n",
    "\n",
    "df.to_sql('consumption', conn, index=False, if_exists='replace')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Connecting to the SQLite Database with LangChain\n",
    "\n",
    "This section establishes a connection to the SQLite database (`consumption.db`) using LangChain's `SQLDatabase` utility.\n",
    "\n",
    "### Steps:\n",
    "1. **Import SQLDatabase utility:** Leverage the `SQLDatabase` class from the LangChain community package.\n",
    "2. **Connect to the database:** Specify the URI of the SQLite database (`sqlite:///consumption.db`) to create an instance of `SQLDatabase`.\n",
    "3. **Inspect the database:**\n",
    "   - Print the SQL dialect used by the database (e.g., `sqlite`).\n",
    "   - Retrieve and display the names of usable tables in the database.\n",
    "   - Fetch and print detailed metadata about the tables to understand their structure.\n",
    "\n",
    "This setup ensures that the database connection is ready for querying and further integration with the LangChain system.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sqlite\n",
      "['consumption']\n",
      "\n",
      "CREATE TABLE consumption (\n",
      "\t\"Creation_Date\" TIMESTAMP, \n",
      "\t\"Purchase_Date\" TIMESTAMP, \n",
      "\t\"Fiscal_Year\" TEXT, \n",
      "\t\"LPA_Number\" TEXT, \n",
      "\t\"Purchase_Order_Number\" TEXT, \n",
      "\t\"Requisition_Number\" TEXT, \n",
      "\t\"Acquisition_Type\" TEXT, \n",
      "\t\"Sub_Acquisition_Type\" TEXT, \n",
      "\t\"Acquisition_Method\" TEXT, \n",
      "\t\"Sub_Acquisition_Method\" TEXT, \n",
      "\t\"Department_Name\" TEXT, \n",
      "\t\"Supplier_Code\" REAL, \n",
      "\t\"Supplier_Name\" TEXT, \n",
      "\t\"Supplier_Qualifications\" TEXT, \n",
      "\t\"Supplier_Zip_Code\" TEXT, \n",
      "\t\"CalCard\" TEXT, \n",
      "\t\"Item_Name\" TEXT, \n",
      "\t\"Item_Description\" TEXT, \n",
      "\t\"Quantity\" REAL, \n",
      "\t\"Unit_Price\" REAL, \n",
      "\t\"Total_Price\" REAL, \n",
      "\t\"Classification_Codes\" TEXT, \n",
      "\t\"Normalized_UNSPSC\" REAL, \n",
      "\t\"Commodity_Title\" TEXT, \n",
      "\t\"Class\" REAL, \n",
      "\t\"Class_Title\" TEXT, \n",
      "\t\"Family\" REAL, \n",
      "\t\"Family_Title\" TEXT, \n",
      "\t\"Segment\" REAL, \n",
      "\t\"Segment_Title\" TEXT, \n",
      "\t\"Location\" TEXT, \n",
      "\t\"Creation_Date_Day\" INTEGER, \n",
      "\t\"Creation_Date_Month\" INTEGER, \n",
      "\t\"Creation_Date_Year\" INTEGER, \n",
      "\t\"Creation_Date_Quarter\" TEXT, \n",
      "\t\"Purchase_Date_Day\" REAL, \n",
      "\t\"Purchase_Date_Month\" REAL, \n",
      "\t\"Purchase_Date_Year\" REAL, \n",
      "\t\"Purchase_Date_Quarter\" TEXT\n",
      ")\n",
      "\n",
      "/*\n",
      "3 rows from consumption table:\n",
      "Creation_Date\tPurchase_Date\tFiscal_Year\tLPA_Number\tPurchase_Order_Number\tRequisition_Number\tAcquisition_Type\tSub_Acquisition_Type\tAcquisition_Method\tSub_Acquisition_Method\tDepartment_Name\tSupplier_Code\tSupplier_Name\tSupplier_Qualifications\tSupplier_Zip_Code\tCalCard\tItem_Name\tItem_Description\tQuantity\tUnit_Price\tTotal_Price\tClassification_Codes\tNormalized_UNSPSC\tCommodity_Title\tClass\tClass_Title\tFamily\tFamily_Title\tSegment\tSegment_Title\tLocation\tCreation_Date_Day\tCreation_Date_Month\tCreation_Date_Year\tCreation_Date_Quarter\tPurchase_Date_Day\tPurchase_Date_Month\tPurchase_Date_Year\tPurchase_Date_Quarter\n",
      "2013-08-27 00:00:00\tNone\t2013-2014\t7-12-70-26\tREQ0011118\tREQ0011118\tIT Goods\tNone\tWSCA/Coop\tNone\tConsumer Affairs, Department of\t1740272.0\tPitney Bowes\tNone\tNone\tNO\tUSB\tUSB\t1.0\t1.0\t1.0\tNone\tNone\tNone\tNone\tNone\tNone\tNone\tNone\tNone\tNone\t27\t8\t2013\t2013Q3\tNone\tNone\tNone\t2013Q3\n",
      "2014-01-29 00:00:00\tNone\t2013-2014\tNone\tREQ0011932\tREQ0011932\tNON-IT Goods\tNone\tInformal Competitive\tNone\tConsumer Affairs, Department of\t1760085.0\tRodea Auto Tech\tNone\tNone\tNO\tTire Disposal\tTire Disposal\t2.0\t2.0\t4.0\t76121504\t76121504.0\tNone\tNone\tNone\tNone\tNone\tNone\tNone\tNone\t29\t1\t2014\t2014Q1\tNone\tNone\tNone\t2014Q1\n",
      "2013-11-01 00:00:00\tNone\t2013-2014\tNone\tREQ0011476\tREQ0011476\tIT Services\tNone\tInformal Competitive\tNone\tConsumer Affairs, Department of\t17224.0\tSmile Business Products, Inc\tNone\t95841\tNO\tLabor\tLabor\t4.5\t150.0\t675.0\tNone\tNone\tNone\tNone\tNone\tNone\tNone\tNone\tNone\t95841\n",
      "(38.662263, -121.346136)\t1\t11\t2013\t2013Q4\tNone\tNone\tNone\t2013Q4\n",
      "*/\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.utilities import SQLDatabase\n",
    "\n",
    "db = SQLDatabase.from_uri(\"sqlite:///consumption.db\")\n",
    "print(db.dialect)\n",
    "print(db.get_usable_table_names())\n",
    "print(db.get_table_info())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great! We've got a SQL database that we can query. Now let's try hooking it up to an LLM.\n",
    "\n",
    "# Hooking the SQL Database to an LLM using Chains\n",
    "\n",
    "In this section, we begin integrating the SQL database with a Large Language Model (LLM) to create a system that answers user queries by leveraging structured data.\n",
    "\n",
    "### Overview of Chains\n",
    "Chains represent a sequence of predictable steps to process input and generate output. In LangGraph, a chain is modeled as a simple sequence of interconnected nodes. \n",
    "\n",
    "For this task, the chain will:\n",
    "1. **Convert the user question into a SQL query.**\n",
    "2. **Execute the query on the database.**\n",
    "3. **Use the query result to generate a natural language answer to the original question.**\n",
    "\n",
    "### Limitations\n",
    "- This system will execute a SQL query for any user input, even irrelevant ones like \"hello.\"\n",
    "\n",
    "### Application State\n",
    "The application state manages the flow of data throughout the chain:\n",
    "- **Input question**: The user’s query.\n",
    "- **Generated query**: The SQL query formulated to answer the question.\n",
    "- **Query result**: The result obtained from executing the SQL query.\n",
    "- **Generated answer**: The final natural language response to the user.\n",
    "\n",
    "We define the state structure as a `TypedDict` to ensure consistency and clarity in data handling:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing_extensions import TypedDict\n",
    "\n",
    "\n",
    "class State(TypedDict):\n",
    "    question: str\n",
    "    query: str\n",
    "    result: str\n",
    "    answer: str"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementing Functions to Operate on Application State\n",
    "\n",
    "In this section, we define functions to process the application state and populate its contents.\n",
    "\n",
    "### Steps to Process State:\n",
    "1. **Convert question to SQL query:** \n",
    "   - The first step is to take the user’s input and generate a SQL query.\n",
    "   - To ensure reliable SQL generation without extra markdown formatting, explanations, or clarifications, we will use LangChain's [structured output](https://langchain-ai.github.io/langgraph/concepts/structured_outputs/) abstraction.\n",
    "\n",
    "2. **Select a Chat Model:**\n",
    "   - We use `ChatOpenAI` as the chat model for this application, specifying `gpt-4o` as the model and setting the temperature to `0` for deterministic outputs.\n",
    "\n",
    "### Note:\n",
    "An OpenAI API key is required to use the `ChatOpenAI` model. Ensure that the `OPENAI_API_KEY` environment variable is set before running the code.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "os.environ[\"OPENAI_API_KEY\"] = os.getenv(\"OPENAI_API_KEY\")\n",
    "from langchain_openai import ChatOpenAI\n",
    "llm = ChatOpenAI(model=\"gpt-4o\", temperature=0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will pull a prompt from the [Prompt Hub](https://smith.langchain.com/hub) to instruct the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\alikh\\anaconda3\\envs\\sm_ct\\lib\\site-packages\\langsmith\\client.py:354: LangSmithMissingAPIKeyWarning: API key must be provided when using hosted LangSmith API\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m System Message \u001b[0m================================\n",
      "\n",
      "Given an input question, create a syntactically correct \u001b[33;1m\u001b[1;3m{dialect}\u001b[0m query to run to help find the answer. Unless the user specifies in his question a specific number of examples they wish to obtain, always limit your query to at most \u001b[33;1m\u001b[1;3m{top_k}\u001b[0m results. You can order the results by a relevant column to return the most interesting examples in the database.\n",
      "\n",
      "Never query for all the columns from a specific table, only ask for a the few relevant columns given the question.\n",
      "\n",
      "Pay attention to use only the column names that you can see in the schema description. Be careful to not query for columns that do not exist. Also, pay attention to which column is in which table.\n",
      "\n",
      "Only use the following tables:\n",
      "\u001b[33;1m\u001b[1;3m{table_info}\u001b[0m\n",
      "\n",
      "Question: \u001b[33;1m\u001b[1;3m{input}\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "from langchain import hub\n",
    "\n",
    "query_prompt_template = hub.pull(\"langchain-ai/sql-query-system-prompt\")\n",
    "\n",
    "assert len(query_prompt_template.messages) == 1\n",
    "query_prompt_template.messages[0].pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The prompt includes several parameters we will need to populate, such as the SQL dialect and table schemas. LangChain's [SQLDatabase](https://python.langchain.com/api_reference/community/utilities/langchain_community.utilities.sql_database.SQLDatabase.html) object includes methods to help with this. Our `write_query` step will just populate these parameters and prompt a model to generate the SQL query:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing_extensions import Annotated\n",
    "\n",
    "class QueryOutput(TypedDict):\n",
    "    \"\"\"Generated SQL query.\"\"\"\n",
    "\n",
    "    query: Annotated[str, ..., \"Syntactically valid SQL query.\"]\n",
    "\n",
    "\n",
    "def write_query(state: State):\n",
    "    \"\"\"Generate SQL query to fetch information.\"\"\"\n",
    "    prompt = query_prompt_template.invoke(\n",
    "        {\n",
    "            \"dialect\": db.dialect,\n",
    "            \"top_k\": 10,\n",
    "            \"table_info\": db.get_table_info(),\n",
    "            \"input\": state[\"question\"],\n",
    "        }\n",
    "    )\n",
    "    structured_llm = llm.with_structured_output(QueryOutput)\n",
    "    result = structured_llm.invoke(prompt)\n",
    "    return {\"query\": result[\"query\"]}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's test it out:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'query': 'SELECT SUM(Total_Price) AS Total_Sum FROM consumption;'}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "write_query({\"question\": \"what is the sum of Total Price?\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Executing SQL Queries in the Chain\n",
    "\n",
    "This step involves executing the SQL query generated by the chain to retrieve results from the database.\n",
    "\n",
    "### Caution:\n",
    "Executing SQL queries directly can be risky, especially when automated. Consider **minimizing database permissions:** Restrict the connection's access to only the necessary tables and data.\n",
    "\n",
    "\n",
    "### Query Execution\n",
    "To execute the query, we will use a tool from the [langchain-community](https://langchain-ai.github.io/langgraph/concepts/architecture/#langchain-community). This tool integrates with the database to run the generated SQL query and return results.\n",
    "\n",
    "### Implementation:\n",
    "The `execute_query` function wraps the query execution process using `QuerySQLDataBaseTool` from LangChain.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.tools.sql_database.tool import QuerySQLDataBaseTool\n",
    "\n",
    "\n",
    "def execute_query(state: State):\n",
    "    \"\"\"Execute SQL query.\"\"\"\n",
    "    execute_query_tool = QuerySQLDataBaseTool(db=db)\n",
    "    return {\"result\": execute_query_tool.invoke(state[\"query\"])}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing this step:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'result': 'Error: (sqlite3.OperationalError) near \"SSELECT\": syntax error\\n[SQL: SSELECT SUM(Total_Price) AS Total_Sum FROM consumption\\';]\\n(Background on this error at: https://sqlalche.me/e/20/e3q8)'}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "execute_query({'query': \"SSELECT SUM(Total_Price) AS Total_Sum FROM consumption';\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate answer\n",
    "\n",
    "Finally, our last step generates an answer to the question given the information pulled from the database:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_answer(state: State):\n",
    "    \"\"\"Answer question using retrieved information as context.\"\"\"\n",
    "    prompt = (\n",
    "        \"Given the following user question, corresponding SQL query, \"\n",
    "        \"and SQL result, answer the user question.\\n\\n\"\n",
    "        f'Question: {state[\"question\"]}\\n'\n",
    "        f'SQL Query: {state[\"query\"]}\\n'\n",
    "        f'SQL Result: {state[\"result\"]}'\n",
    "    )\n",
    "    response = llm.invoke(prompt)\n",
    "    return {\"answer\": response.content}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Orchestrating with LangGraph\n",
    "\n",
    "Finally, we compile our application into a single `graph` object. In this case, we are just connecting the three steps into a single sequence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import START, StateGraph\n",
    "\n",
    "graph_builder = StateGraph(State).add_sequence(\n",
    "    [write_query, execute_query, generate_answer]\n",
    ")\n",
    "graph_builder.add_edge(START, \"write_query\")\n",
    "graph = graph_builder.compile()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LangGraph also comes with built-in utilities for visualizing the control flow of your application:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import Image, display\n",
    "\n",
    "display(Image(graph.get_graph().draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's test our application! Note that we can stream the results of individual steps:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'write_query': {'query': 'SELECT SUM(Total_Price) as Total_Spent FROM consumption WHERE Purchase_Date_Year = 2014 AND Purchase_Date_Month = 7;'}}\n",
      "{'execute_query': {'result': '[(2465880295.540002,)]'}}\n",
      "{'generate_answer': {'answer': 'The total amount of money spent in July 2014 is 2,465,880,295.54.'}}\n"
     ]
    }
   ],
   "source": [
    "for step in graph.stream(\n",
    "    {\"question\": \"what is Total amnount of money spent in july 2014?\"}, stream_mode=\"updates\"\n",
    "):\n",
    "    print(step)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Finalizing the Application: Generating Answers\n",
    "\n",
    "This section implements the final functionality of the application. Given a user question as a string, the application:\n",
    "1. Processes the question to generate a SQL query.\n",
    "2. Executes the query on the database.\n",
    "3. Retrieves the result and generates a natural language answer.\n",
    "\n",
    "### Function Overview:\n",
    "- **Input:** A string representing the user question.\n",
    "- **Process:** The application uses the LangGraph workflow to handle the input, execute a query, and interpret the result.\n",
    "- **Output:** A natural language answer to the user’s question.\n",
    "\n",
    "The implementation is wrapped in a function for reusability, allowing the app to handle various queries seamlessly. Below is the function definition and an example usage.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The total number of orders in July 2014 is 11,839.\n"
     ]
    }
   ],
   "source": [
    "def get_answer(question: str) -> str:\n",
    "    \"\"\"\n",
    "    Takes a user question as input and returns a natural language answer generated \n",
    "    by the application, which queries a SQL database to retrieve relevant data.\n",
    "\n",
    "    Parameters:\n",
    "    - question (str): The user question to be answered.\n",
    "\n",
    "    Returns:\n",
    "    - str: The generated natural language answer to the question.\n",
    "    \"\"\"\n",
    "    # Use the LangGraph `graph.invoke` method to process the input question\n",
    "    # The result is fetched in streaming mode to provide updates, and the final answer is extracted\n",
    "    answer = graph.invoke({\"question\": question}, stream_mode=\"updates\")[-1][\"generate_answer\"][\"answer\"]\n",
    "    return answer\n",
    "\n",
    "question = \"what is Total number of orders in july 2014?\"\n",
    "print(get_answer(question))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation\n",
    "\n",
    "In this step, we will evaluate the performance of the chatting assistant by testing it with a variety of sample queries. The goal is to ensure that the assistant provides accurate, relevant, and reliable responses based on the procurement data.\n",
    "\n",
    "### Evaluation Process:\n",
    "1. **Test with Sample Queries:**\n",
    "   - We will input a range of questions related to procurement data, similar to the real-world use cases the assistant might encounter.\n",
    "   - For each question, we will first run a Python function to generate the expected result, which will serve as the **ground truth**. Then, we will pass the same question through the assistant to get its generated response using the `get_answer` function.\n",
    "\n",
    "2. **Performance Assessment:**\n",
    "   -  We will compare the assistant’s answers to the expected results (ground truth) obtained from the Python functions. This comparison will help evaluate how accurately the assistant answers the questions.\n",
    "\n",
    "By comparing the assistant’s responses against the expected outcomes, we will assess its ability to answer various types of procurement-related queries. This process ensures the assistant's reliability and effectiveness in providing meaningful insights from the dataset.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 1: Total Number of Orders in a Specific Time Period\n",
    "\n",
    "To evaluate the assistant's performance for this question, we will compare its response with the ground truth, generated using the `total_orders_in_time_period` Python function. This function calculates the number of orders within a given date range.\n",
    "\n",
    "\n",
    "We'll use this function to get the expected result, then compare it with the assistant’s answer.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expected Output: \n",
      "28443\n",
      "-*--*--*--*--*--*--*--*--*--*--*--*--*--*--*--*--*--*--*--*-\n",
      "Assistant output: \n",
      "The total number of orders between '2013-07-01' and '2013-09-30' is 28,443.\n"
     ]
    }
   ],
   "source": [
    "def total_orders_in_time_period(df, start_date, end_date):\n",
    "    df['Creation_Date'] = pd.to_datetime(df['Creation_Date'])\n",
    "    filtered_df = df[(df['Creation_Date'] >= start_date) & (df['Creation_Date'] <= end_date)]\n",
    "    return len(filtered_df)\n",
    "\n",
    "# Example Usage\n",
    "start_date = '2013-07-01'\n",
    "end_date = '2013-09-30'\n",
    "print(\"Expected Output: \")\n",
    "print(total_orders_in_time_period(df, start_date, end_date))  # Orders in Q1 of FY 2023-24\n",
    "print(\"-*-\"*20)\n",
    "print(\"Assistant output: \")\n",
    "print(get_answer(\"what is Total number of orders between '2013-07-01' and '2013-09-30'? consider only the date not the hours\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 2: Identify the Quarter with the Highest Spending\n",
    "\n",
    "To evaluate the assistant’s performance on this question, we will compare its response to the ground truth, which is calculated using the `highest_spending_quarter` Python function. This function identifies the quarter with the highest total spending from the procurement data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expected Output: \n",
      "Quarter with the highest spending: 2015Q2, Amount: $28804820727.65\n",
      "-*--*--*--*--*--*--*--*--*--*--*--*--*--*--*--*--*--*--*--*-\n",
      "Assistant output: \n",
      "The quarter with the highest spending is the second quarter of 2015 (2015Q2), with a total spending of 28,804,820,727.65.\n"
     ]
    }
   ],
   "source": [
    "def highest_spending_quarter(df):\n",
    "    df['Creation_Date'] = pd.to_datetime(df['Creation_Date'])\n",
    "    df['Fiscal Quarter'] = df['Creation_Date'].dt.to_period('Q')\n",
    "    spending_by_quarter = df.groupby('Fiscal Quarter')['Total_Price'].sum()\n",
    "    highest_quarter = spending_by_quarter.idxmax()\n",
    "    highest_spending = spending_by_quarter.max()\n",
    "    return highest_quarter, highest_spending\n",
    "\n",
    "# Example Usage:\n",
    "quarter, spending = highest_spending_quarter(df)\n",
    "print(\"Expected Output: \")\n",
    "print(f\"Quarter with the highest spending: {quarter}, Amount: ${spending:.2f}\")\n",
    "print(\"-*-\"*20)\n",
    "print(\"Assistant output: \")\n",
    "print(get_answer(\"what is the the quarter with the highest spending?\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 3: Frequently Ordered Line Items\n",
    "\n",
    "For this question, we will evaluate the assistant’s response by comparing it with the ground truth, which is obtained using the `frequently_ordered_items` Python function. This function identifies the most frequently ordered items from the procurement data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expected Output: \n",
      "Medical Supplies               2916\n",
      "Contract                       2092\n",
      "ew                             1539\n",
      "Expert Witness                 1317\n",
      "medical vocational training    1092\n",
      "Toner                          1046\n",
      "contract                        983\n",
      "Office Supplies                 959\n",
      "Dental Supplies                 772\n",
      "toner                           658\n",
      "Name: Item_Name, dtype: int64\n",
      "-*--*--*--*--*--*--*--*--*--*--*--*--*--*--*--*--*--*--*--*-\n",
      "Assistant output: \n",
      "The most 10 frequently ordered items are:\n",
      "\n",
      "1. Medical Supplies - 2916 orders\n",
      "2. Contract - 2092 orders\n",
      "3. ew - 1539 orders\n",
      "4. Expert Witness - 1317 orders\n",
      "5. Medical Vocational Training - 1092 orders\n",
      "6. Toner - 1046 orders\n",
      "7. Contract (lowercase) - 983 orders\n",
      "8. Office Supplies - 959 orders\n",
      "9. Dental Supplies - 772 orders\n",
      "10. Toner (lowercase) - 658 orders\n"
     ]
    }
   ],
   "source": [
    "def frequently_ordered_items(df, top_n=10):\n",
    "    # Count the frequency of each item and return the top 10\n",
    "    item_frequency = df['Item_Name'].value_counts().head(top_n)\n",
    "    return item_frequency\n",
    "\n",
    "# Example Usage\n",
    "top_10_items = frequently_ordered_items(df, top_n=10)\n",
    "print(\"Expected Output: \")\n",
    "print(top_10_items)\n",
    "print(\"-*-\"*20)\n",
    "print(\"Assistant output: \")\n",
    "print(get_answer(\"what are the most 10 frequently ordered items?\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 4: Total Amount Spent by Department in a Specific Fiscal Year\n",
    "\n",
    "To evaluate the assistant’s performance for this question, we will compare its response with the ground truth, generated using the `total_spent_by_department` Python function. This function calculates the total amount spent by each department in a specified fiscal year.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expected Output: \n",
      "Department_Name\n",
      "Health Care Services, Department of              2.845645e+10\n",
      "Corrections and Rehabilitation, Department of    2.488082e+09\n",
      "Transportation, Department of                    1.556413e+09\n",
      "Water Resources, Department of                   1.168074e+09\n",
      "Correctional Health Care Services                8.235272e+08\n",
      "Social Services, Department of                   7.907241e+08\n",
      "State Hospitals, Department of                   7.354055e+08\n",
      "High Speed Rail Authority, California            7.261482e+08\n",
      "Public Health, Department of                     5.923648e+08\n",
      "Personnel Administration, Department of          3.716678e+08\n",
      "Name: Total_Price, dtype: float64\n",
      "-*--*--*--*--*--*--*--*--*--*--*--*--*--*--*--*--*--*--*--*-\n",
      "Assistant output: \n",
      "The top 10 spending departments in fiscal year 2013-2014 are:\n",
      "\n",
      "1. Health Care Services, Department of - $28,456,453,981.89\n",
      "2. Corrections and Rehabilitation, Department of - $2,488,081,948.85\n",
      "3. Transportation, Department of - $1,556,413,302.31\n",
      "4. Water Resources, Department of - $1,168,074,281.54\n",
      "5. Correctional Health Care Services - $823,527,156.53\n",
      "6. Social Services, Department of - $790,724,136.61\n",
      "7. State Hospitals, Department of - $735,405,549.71\n",
      "8. High Speed Rail Authority, California - $726,148,181.75\n",
      "9. Public Health, Department of - $592,364,758.59\n",
      "10. Personnel Administration, Department of - $371,667,771.51\n"
     ]
    }
   ],
   "source": [
    "def total_spent_by_department(df, fiscal_year, top_n=10):\n",
    "    df['Fiscal_Year'] = df['Fiscal_Year'].astype(str)\n",
    "    filtered_df = df[df['Fiscal_Year'] == fiscal_year]\n",
    "    department_spending = filtered_df.groupby('Department_Name')['Total_Price'].sum()\n",
    "    top_departments = department_spending.sort_values(ascending=False).head(top_n)\n",
    "    return top_departments\n",
    "\n",
    "# Example Usage:\n",
    "fiscal_year = '2013-2014'\n",
    "print(\"Expected Output: \")\n",
    "print(total_spent_by_department(df, fiscal_year))  # Top 10 spending departments in FY 2013-2014\n",
    "print(\"-*-\"*20)\n",
    "print(\"Assistant output: \") \n",
    "print(get_answer(\"what are the top 10 spending departments in fiscal year 2013-2014?\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 5: Items Purchased from Certified Suppliers\n",
    "\n",
    "To evaluate the assistant’s performance for this question, we will compare its response with the ground truth, generated using the `items_from_certified_suppliers` Python function. This function retrieves items purchased from suppliers that meet specific certifications.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expected Output: \n",
      "Supplier_Name\n",
      "TAGG Industries, Inc.                                    3983\n",
      "San Joaquin Distributors, Inc.                           3510\n",
      "River City Office Supply                                 2643\n",
      "THE PRIMARY SOURCE                                       2284\n",
      "Horizon Business Solutions, Inc.                         2273\n",
      "Merritt Business Supplies                                2169\n",
      "Christian Bartels Enterprises Inc. dba CB Enterprises    2052\n",
      "Bay Medical Co., Inc                                     1895\n",
      "Adolph Inc.                                              1868\n",
      "Office Xpress Inc                                        1817\n",
      "dtype: int64\n",
      "-*--*--*--*--*--*--*--*--*--*--*--*--*--*--*--*--*--*--*--*-\n",
      "Assistant output: \n",
      "The number of orders placed with certified suppliers, grouped by each supplier, are as follows:\n",
      "\n",
      "1. TAGG Industries, Inc. - 3,983 orders\n",
      "2. San Joaquin Distributors, Inc. - 3,510 orders\n",
      "3. River City Office Supply - 2,643 orders\n",
      "4. THE PRIMARY SOURCE - 2,284 orders\n",
      "5. Horizon Business Solutions, Inc. - 2,273 orders\n",
      "6. Merritt Business Supplies - 2,169 orders\n",
      "7. Christian Bartels Enterprises Inc. dba CB Enterprises - 2,052 orders\n",
      "8. Bay Medical Co., Inc - 1,895 orders\n",
      "9. Adolph Inc. - 1,868 orders\n",
      "10. Office Xpress Inc - 1,817 orders\n"
     ]
    }
   ],
   "source": [
    "def orders_from_certified_suppliers(df, qualifications):\n",
    "    # Filter the DataFrame for suppliers with specified qualifications\n",
    "    filtered_df = df[df['Supplier_Qualifications'].str.contains(qualifications, na=False)]\n",
    "\n",
    "    # Count the number of orders per supplier\n",
    "    supplier_order_count = filtered_df.groupby('Supplier_Name').size().sort_values(ascending=False)\n",
    "\n",
    "    return supplier_order_count.sort_values(ascending=False).head(10)\n",
    "# Example Usage\n",
    "qualifications = 'SB|SBE|DVBE'  # Small Business, Small Business Enterprise, Disabled Veteran Business Enterprise\n",
    "print(\"Expected Output: \")\n",
    "print(orders_from_certified_suppliers(df, qualifications))\n",
    "print(\"-*-\"*20)\n",
    "print(\"Assistant output: \")\n",
    "print(get_answer(\"How many orders were placed with certified suppliers, grouped by each supplier?\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 6: Most Expensive Supplier\n",
    "\n",
    "For this question, we will evaluate the assistant’s response by comparing it with the ground truth, which is generated using the `most_expensive_supplier` Python function. This function identifies the supplier with the highest total spending.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expected Output: \n",
      "Most expensive supplier: Health Net Community Solutions, Inc., Amount spent: $13587059000.06\n",
      "-*--*--*--*--*--*--*--*--*--*--*--*--*--*--*--*--*--*--*--*-\n",
      "Assistant output: \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The most expensive supplier based on the total spent money is \"Health Net Community Solutions, Inc.\" with a total spent amount of 13,587,059,000.06.\n"
     ]
    }
   ],
   "source": [
    "def most_expensive_supplier(df):\n",
    "    supplier_spending = df.groupby('Supplier_Name')['Total_Price'].sum()\n",
    "    return supplier_spending.idxmax(), supplier_spending.max()\n",
    "\n",
    "# Example Usage\n",
    "supplier, spending = most_expensive_supplier(df)\n",
    "print(\"Expected Output: \")\n",
    "print(f\"Most expensive supplier: {supplier}, Amount spent: ${spending:.2f}\")\n",
    "print(\"-*-\"*20)\n",
    "print(\"Assistant output: \")\n",
    "print(get_answer(\"What is the most expensive supplier based on the total spent money?\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 7: Total Orders by Month\n",
    "\n",
    "For this question, we will evaluate the assistant’s response by comparing it with the ground truth, which is generated using the `total_orders_by_month` Python function. This function calculates the total number of orders placed in a specific month of a given year.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expected Output: \n",
      "11391\n",
      "-*--*--*--*--*--*--*--*--*--*--*--*--*--*--*--*--*--*--*--*-\n",
      "Assistant output: \n",
      "A total of 11,391 orders were placed in July 2013.\n"
     ]
    }
   ],
   "source": [
    "def total_orders_by_month(df, year, month):\n",
    "    orders_in_month = df[(df['Purchase_Date_Year'] == year) & (df['Purchase_Date_Month'] == month)]\n",
    "    return len(orders_in_month)\n",
    "\n",
    "# Example Usage\n",
    "year = 2013\n",
    "month = 7  # July\n",
    "print(\"Expected Output: \")\n",
    "print(total_orders_by_month(df, year, month))\n",
    "print(\"-*-\"*20)\n",
    "print(\"Assistant output: \")\n",
    "print(get_answer(\"how many orders were placed in july 2013?\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 8: Spending by Specific Month\n",
    "\n",
    "For this question, we will evaluate the assistant’s response by comparing it with the ground truth, which is generated using the `spending_by_month` Python function. This function calculates the total spending in a specific month of a given year.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expected Output: \n",
      "2220647365.84\n",
      "-*--*--*--*--*--*--*--*--*--*--*--*--*--*--*--*--*--*--*--*-\n",
      "Assistant output: \n",
      "The total amount spent in July 2013 was 2,220,647,365.84.\n"
     ]
    }
   ],
   "source": [
    "def spending_by_month(df, year, month):\n",
    "    spending_in_month = df[(df['Purchase_Date_Year'] == year) & (df['Purchase_Date_Month'] == month)]['Total_Price'].sum()\n",
    "    return spending_in_month\n",
    "\n",
    "# Example Usage\n",
    "year = 2013\n",
    "month = 7  # July\n",
    "print(\"Expected Output: \")\n",
    "print(spending_by_month(df, year, month))\n",
    "print(\"-*-\"*20)\n",
    "print(\"Assistant output: \")\n",
    "print(get_answer(\"how much was spent in july 2013?\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sm_ct",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
